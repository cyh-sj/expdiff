<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- <meta name="description" -->
        <!-- content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos."> -->
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF"> -->
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <title>ExpDiff</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ExpDiff: Generating High-fidelity Dynamic Facial Expressions with BRDF Textures via Diffusion Model</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://cyh-sj.github.io/">
                Yuhao Cheng</a>,
            </span>
            <span class="author-block">
                Xuanchen Li,
            </span>
            <span class="author-block">
              <a href="https://xingyuren.github.io/">
                Xingyu Ren</a>
            </span>
            <span class="author-block">
              Zhuo Chen,
            </span>
            <span class="author-block">
              Xiaokang Yang,
            </span>
            <span class="author-block">
              <a href="https://daodaofr.github.io/">
                Yichao Yan</a><sup>&dagger;</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ai.sjtu.edu.cn/">MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University</a>
            </span>
          </div>
          
          <div class="is-size-6">
            <span>(<sup>&dagger;</sup>Corresponding author)</span>
          </div>
          <!-- <div class="is-size-5 has-text-weight-bold">
              ECCV 2024
          </div> -->




          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://github.com/cyh-sj/expdiff"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=2XvqhwWWBsI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/cyh-sj/expdiff"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/cyh-sj/expdiff"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset (Coming Soon)</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img class="img-responsive" src="./static/images/teaserbrdf.png" alt="Teaser">
      <h2 class="subtitle has-text-justified">
        <span class="Topo4D">An example of our dynamic facial expressions generation method. Given a neutral-expression mesh and texture maps as input, our framework enables the generation of FACS-compliant expression meshes with pore-level dynamic BRDF textures through expression text prompts, achieving physically-based photo-realistic rendering.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            3D facial generation is a critical task for immersive multimedia applications, where the key challenge lies in synthesizing vivid expression meshes with corresponding dynamical textures. 
Current approaches still have limitations in geometric-textural coherence and dynamic reflectance generation. 
To address these challenges, we present ExpDiff, a framework that generates expression meshes and dynamic BRDF textures from a single neutral-expression face. To achieve effective generation, we propose an attention-based diffusion model to learn the relationship among different expressions.
To ensure correspondence between geometry and texture, we introduce a unified representation that explicitly models geometric-textural interaction, and then encodes them by models trained on large-scale datasets into a latent space to maintain generalization.
To achieve semantically coherent and physically consistent generation,  we propose to guide the denoising direction with specially designed textual prompts. 
We further construct two novel dynamic expression datasets to train the models, setting new standards for asset quality (J-Reflectance) and identity diversity (FFHQ-BRDFExp), which are publicly released to advance the community. Extensive experiments demonstrate our method's superior performance in photorealistic facial animation synthesis. 
          </p>
        
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pipeline</h2>
        <img class="img-responsive" src="./static/images/pipelinebrdf.png" alt="Pipeline">
        <div class="content has-text-justified">
        <span class="Pipeline">Overview of our proposed ExpDiff. Given neutral models and expression models, we first represent them in the unified representation and project them into the latent space through a frozen encoder. Then, we propose an attention-based diffusion model for expression asset generation. The textual prompts are encoded by CLIP to obtain semantic information, leading the denoising direction of the diffusion model.
        </div>
      </div>
    </div>
    <!--/ Paper Pipeline. -->
  </div>
</section>


<!-- Paper Pipeline. -->

<section class="section">
  <div class="container is-max-desktop">
<div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">J-Reflectance Dataset</h2>
        <img class="img-responsive" src="./static/images/pipeline.png" alt="Pipeline">
        <div class="content has-text-justified">
        <span class="Pipeline">Overview of our proposed ExpDiff. Given neutral models and expression models, we first represent them in the unified representation and project them into the latent space through a frozen encoder. Then, we propose an attention-based diffusion model for expression asset generation. The textual prompts are encoded by CLIP to obtain semantic information, leading the denoising direction of the diffusion model.
        </div>
      </div>
    </div>
    <!--/ Paper Pipeline. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        
        <h3 class="title is-4">Reconstruction Results</h3>
        <div class="content has-text-justified">
          <p>
            <span class="dnerf">Topo4D</span> can generate dynamic temporal-consistent meshes
and corresponding 8K texture maps with pore-level details from calibrated multi-view videos. 
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/talk.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="content has-text-justified">
          <p>
            <span class="dnerf">Topo4D</span> can capture subtle facial changes and various extreme expressions, representing muscle tremors and dynamic wrinkles.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/exp1.mp4"
                    type="video/mp4">
          </video>
        </div>

<!--         <div class="content has-text-justified">
          <p>
            <span class="dnerf">Topo4D</span> can capture subtle facial changes and various extreme expressions, representing muscle tremors and dynamic wrinkles.
          </p>
        </div> -->
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="100%">
            <source src="./static/videos/exp2.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
    <!--/ Results. -->

  </div>
</section>
  

  
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@inproceedings{cheng2025expdiff,
  title={ExpDiff: Generating High-fidelity Dynamic Facial Expressions with BRDF Textures via Diffusion Model},
  author={Cheng, Yuhao and Li, Xuanchen and Ren, Xingyu and Chen, Zhuo and Yang, Xiaokang and Yan, Yichao},
  year={2025}
}
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the website <a href="https://github.com/nerfies/nerfies.github.io">template</a> from this,
            many thanks for their great help!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
